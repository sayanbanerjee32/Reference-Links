# Reference-Links
Curated list of articles for ML/AI/NLP


## Deep Learning:

* The Perceptron Learning Algorithm and its Convergence: https://www.cse.iitb.ac.in/~shivaram/teaching/old/cs344+386-s2017/resources/classnote-1.pdf
* Deep Dive into Math Behind Deep Networks: https://towardsdatascience.com/https-medium-com-piotr-skalski92-deep-dive-into-deep-networks-math-17660bc376ba
* Recent Advances for a Better Understanding of Deep Learning âˆ’ Part I: https://towardsdatascience.com/recent-advances-for-a-better-understanding-of-deep-learning-part-i-5ce34d1cc914
* using neural nets to recognize handwritten digits: http://neuralnetworksanddeeplearning.com/chap1.html
* Tinker with Neural Networks in browser: https://playground.tensorflow.org
* Dimensions and manifolds: https://datascience.stackexchange.com/questions/5694/dimensionality-and-manifold
* Play with Generative Adverserial Networks: https://poloclub.github.io/ganlab/
* Overfitting and how to prevent it: https://hackernoon.com/memorizing-is-not-learning-6-tricks-to-prevent-overfitting-in-machine-learning-820b091dc42
* 37 reasons for neural n/w not working properly: https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607

### CNN and Image Processing:

* Why do we need to normalize the images before we put them into CNN? : https://stats.stackexchange.com/questions/185853/why-do-we-need-to-normalize-the-images-before-we-put-them-into-cnn
* Neural Network data type conversion - float from int? : https://datascience.stackexchange.com/questions/13636/neural-network-data-type-conversion-float-from-int
* Image Pre-processing (Keras): https://keras.io/preprocessing/image/
* Trick to prevent Overfitting: https://hackernoon.com/memorizing-is-not-learning-6-tricks-to-prevent-overfitting-in-machine-learning-820b091dc42
* keras callbacks: https://keras.io/callbacks/
* How to Check-Point Deep Learning Models in Keras: https://machinelearningmastery.com/check-point-deep-learning-models-keras/
* In Depth understanding of Convolutions: http://timdettmers.com/2015/03/26/convolution-deep-learning/
* friendly introduction to Cross Entropy: https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/
* Understanding Cross Entropy Loss - Visual Information Theory: http://timdettmers.com/2015/03/26/convolution-deep-learning/
* Papers on imp CNN architectures: https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html
* CNN using numpy: https://becominghuman.ai/only-numpy-implementing-convolutional-neural-network-using-numpy-deriving-forward-feed-and-back-458a5250d6e4
* Image Transformations Using OpenCV: https://docs.opencv.org/trunk/d9/d61/tutorial_py_morphological_ops.html
* List of Open Source **Medical Image Analysis** Softwares:http://www0.cs.ucl.ac.uk/opensource_mia_ws_2012/links.html
* Natural Images: https://stats.stackexchange.com/questions/25737/definition-of-natural-images-in-the-context-of-machine-learning
* ResNet - understanding the bottleneck unit: https://stats.stackexchange.com/questions/347280/regarding-the-understanding-of-bottleneck-unit-of-resnet

* https://github.com/anujshah1003/VQA-Demo-GUI
* https://iamaaditya.github.io/2016/04/visual_question_answering_demo_notebook

* CNN+LSTM: https://machinelearningmastery.com/cnn-long-short-term-memory-networks/


#### Data
* Chest X-ray data: https://www.kaggle.com/nih-chest-xrays

## References (technical):

* plotting boxplots in plotly in python: https://plot.ly/python/box-plots/
* extract high correlation values: https://stackoverflow.com/questions/17778394/list-highest-correlation-pairs-from-a-large-correlation-matrix-in-pandas
* converting group by object to data frame (also how to avoid converting columns to indices when doing group by):https://stackoverflow.com/questions/10373660/converting-a-pandas-groupby-object-to-dataframe
* **matplotlib** basic tutorial: https://www.datacamp.com/community/tutorials/matplotlib-tutorial-python
* parametric and non-parametric ml methods: https://machinelearningmastery.com/parametric-and-nonparametric-machine-learning-algorithms/
* Stability Selection vs RFE (Recursive Feature Elimination): http://blog.datadive.net/selecting-good-features-part-iv-stability-selection-rfe-and-everything-side-by-side/

* **Scikit learn**: http://scikit-learn.org/stable/index.html

## feature scaling
* Standardisation vs Normalization:  https://stackoverflow.com/questions/32108179/linear-regression-normalization-vs-standardization
* Importance of Feature Scaling: http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html
* feature Scaling with scikit-learn (good): http://benalexkeen.com/feature-scaling-with-scikit-learn/
* about feature scaling (bit mathematical): http://sebastianraschka.com/Articles/2014_about_feature_scaling.html


* How is Bayesian classifer different from MLE classifier?: https://stats.stackexchange.com/questions/74082/what-is-the-difference-in-bayesian-estimate-and-maximum-likelihood-estimate
* ROC : https://stats.stackexchange.com/questions/105501/understanding-roc-curve
* ROC detailed analysis: http://mlwiki.org/index.php/ROC_Analysis
* Cross Validation - need for test set: https://stats.stackexchange.com/questions/223408/how-does-k-fold-cross-validation-fit-in-the-context-of-training-validation-testi AND
https://stackoverflow.com/questions/43663365/cross-validation-use-testing-set-or-validation-set-to-predict
* K Modes Clustering: https://shapeofdata.wordpress.com/2014/03/04/k-modes/
* Hirarchial Clustering: http://www.saedsayad.com/clustering_hierarchical.htm
* Linkage methods of hierarchical agglomerative cluster analysis (HAC): https://stats.stackexchange.com/questions/195446/choosing-the-right-linkage-method-for-hierarchical-clustering
* why LASSO shrinkag works: https://stats.stackexchange.com/questions/179864/why-does-shrinkage-work
* p value: https://www.statsdirect.com/help/basics/p_values.htm
* multicollinearity in regression analysis: http://statisticsbyjim.com/regression/multicollinearity-in-regression-analysis/
* Effect of multicollinearity on Ordinary Least Squares solution for regression: https://en.wikipedia.org/wiki/Multicollinearity
* Why is gradient descent or optimization methods required at all if cost function minima can be found directly say by using linear algebra or differentiation ? : https://stats.stackexchange.com/questions/212619/why-is-gradient-descent-required
https://stats.stackexchange.com/questions/278755/why-use-gradient-descent-for-linear-regression-when-a-closed-form-math-solution
* normality tests in python: https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/
* parametric significance tests in python: https://machinelearningmastery.com/parametric-statistical-significance-tests-in-python/
* non-parametric significance tests in python: https://machinelearningmastery.com/nonparametric-statistical-significance-tests-in-python/
* Introduction to Matrix Decomposition: https://machinelearningmastery.com/introduction-to-matrix-decompositions-for-machine-learning/
* How to Compare ML models: https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/
* Beginners guide to Jupyter Notebooks: https://www.analyticsvidhya.com/blog/2018/05/starters-guide-jupyter-notebook/?utm_source=feedburner&utm_medium=email&utm_campaign=Feed%3A+AnalyticsVidhya+%28Analytics+Vidhya%29
* matplotlib plotting in 2D and 3D: http://nbviewer.jupyter.org/github/jrjohansson/scientific-python-lectures/blob/master/Lecture-4-Matplotlib.ipynb
* Computational Quantum Mechanics with Python: http://jrjohansson.github.io/
* difference between generative and discriminative algorithm: https://stackoverflow.com/questions/879432/what-is-the-difference-between-a-generative-and-discriminative-algorithm
* What is the difference between Liklihood and probability: https://stackoverflow.com/questions/879432/what-is-the-difference-between-a-generative-and-discriminative-algorithm

#### Feature reduction:

* feature reduction using varrank: https://cran.r-project.org/web/packages/varrank/vignettes/varrank.html

**metrics for classification models

* Top 15: https://www.machinelearningplus.com/machine-learning/evaluation-metrics-classification-models-r/

**Pipelines in sklearn**

* Pipelines and composite estimators: https://scikit-learn.org/stable/modules/compose.html#
* Deep dive into sklearn pipelines: https://www.kaggle.com/baghern/a-deep-dive-into-sklearn-pipelines
* Feature Union: https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html#sklearn.pipeline.FeatureUnion
* Column Transformer with Heterogeneous Data Sources: https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer.html#sphx-glr-auto-examples-compose-plot-column-transformer-py

## Boosting:
* A gentle introduction to boosting algos: https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/
* CatBoost Algorithm resources: https://tech.yandex.com/catboost/
* Light GBM: http://lightgbm.readthedocs.io/en/latest/index.html
* Light GBM github: https://github.com/Microsoft/LightGBM
* XGBoost Conceptual Understanding of Algo: http://xgboost.readthedocs.io/en/latest/model.html
* XGBoost Site: http://xgboost.readthedocs.io/en/latest/


* Difference b/w size and count with groupby in pandas: https://stackoverflow.com/questions/33346591/what-is-the-difference-between-size-and-count-in-pandas
* ML crash course by google: https://developers.google.com/machine-learning/crash-course/prereqs-and-prework
* pandas regex to create columns: https://chrisalbon.com/python/data_wrangling/pandas_regex_to_create_columns/
* regex in python and pandas: https://www.dataquest.io/blog/regular-expressions-data-scientists/

* Book on Feature Engineering (Max Kuhn): http://www.feat.engineering/
* Understanding Cost Functions (video series): https://www.youtube.com/watch?v=euhATa4wgzo&index=1&list=PLNlkREaquqc6WUPMRicPbEvLyZe-7b-GT
* Build better predictive models using segmentation: https://www.analyticsvidhya.com/blog/2016/02/guide-build-predictive-models-segmentation/
* metrics for model evaluation: http://scikit-learn.org/stable/modules/model_evaluation.html

* using AWS for Deep Learning: https://machinelearningmastery.com/develop-evaluate-large-deep-learning-models-keras-amazon-web-services/

**PCA**
* variance in PCA explained: https://ro-che.info/articles/2017-12-11-pca-explained-variance

**t-SNE**
* Laurens van der Maaten's (creator of t-SNE) website: https://lvdmaaten.github.io/tsne/
* Visualising data using t-SNE: Journal of Machine Learning Research: http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf
* How to use t-SNE effectively: https://distill.pub/2016/misread-tsne/

**ICA**
* Stanford notes on ICA: http://cs229.stanford.edu/notes/cs229-notes11.pdf

## Docker
* https://www.analyticsvidhya.com/blog/2017/11/reproducible-data-science-docker-for-data-science/
* Docker for ML: https://pratos.github.io/2017-04-24/docker-for-data-science-part-1/
* conceptual - introduction to VM's and Docker: https://medium.freecodecamp.org/a-beginner-friendly-introduction-to-containers-vms-and-docker-79a9e3e119b

#### Handling imbalanced data set:
* how to handle imbalanced data with code: https://elitedatascience.com/imbalanced-classes
* good read: https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/
* concept read: https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/
* imbalanced-learn library: https://github.com/scikit-learn-contrib/imbalanced-learn
* anomaly detection in python: https://www.datascience.com/blog/python-anomaly-detection
* scikit learn novelty and outlier detection: https://www.datascience.com/blog/python-anomaly-detection
* Imbalanced data handling tutorial in Python: https://blog.dominodatalab.com/imbalanced-datasets/

## NLP:
* NLTK Book: http://www.nltk.org/book/ 
* SpaCy: Industrial grad NLP: https://spacy.io/
* Genism: https://radimrehurek.com/gensim/index.html
* NLTK tutorial: https://pythonprogramming.net/tokenizing-words-sentences-nltk-tutorial/

* jaccard distance using NLP: https://python.gotrained.com/nltk-edit-distance-jaccard-distance/#Jaccard_Distance

* Lyric Analysis with NLP and ML in R part 1: https://www.datacamp.com/community/tutorials/R-nlp-machine-learning
* Lyric Analysis with NLP and ML in R part 2A:https://www.datacamp.com/community/tutorials/R-nlp-machine-learning
* Lyric Analysis with NLP and ML in R part 2B:https://www.datacamp.com/community/tutorials/sentiment-analysis-R

* Text Encoding Unicode: https://docs.python.org/3/howto/unicode.html

* Roudup of Python NLP libraries: https://nlpforhackers.io/libraries/

* Spacy Tutorial (AV): https://www.analyticsvidhya.com/blog/2017/04/natural-language-processing-made-easy-using-spacy-%E2%80%8Bin-python/
* SpaCy Tutorial: https://nlpforhackers.io/complete-guide-to-spacy/

* Generate text using word level neural language model: https://machinelearningmastery.com/how-to-develop-a-word-level-neural-language-model-in-keras/
* Generate text using LSTM: https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/

* SIF embeddings implementation: https://www.kaggle.com/procode/sif-embeddings-got-69-accuracy

**Ontology based text classification**: https://sci2lab.github.io/mehdi/icsc2014.pdf

**fast text analysis using Vowpal Wabbit :** https://www.kaggle.com/kashnitsky/vowpal-wabbit-tutorial-blazingly-fast-learning

#### transfer learning in NLP:

* BERT: https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html

* BERT Research Paper: https://arxiv.org/abs/1810.04805 
* blog: http://jalammar.github.io/
* Blog for understanding ELMO and BERT: http://jalammar.github.io/illustrated-bert/
* ULMFIT tutorial: https://www.analyticsvidhya.com/blog/2018/11/tutorial-text-classification-ulmfit-fastai-library/
* DSSM: https://www.microsoft.com/en-us/research/project/dssm/
* Q&A model: https://towardsdatascience.com/nlp-building-a-question-answering-model-ed0529a68c54
* XLnet https://towardsdatascience.com/what-is-xlnet-and-why-it-outperforms-bert-8d8fce710335
* XLNet https://github.com/zihangdai/xlnet
* BiDAF- https://arxiv.org/abs/1611.01603
 
#### Anomaly detection

* https://arxiv.org/pdf/1701.01325.pdf




### XGBoost Installation:

* check you python version - by opening CMD and typing python -> ENTER
* Go to this link and search on XGBoost: https://www.lfd.uci.edu/~gohlke/pythonlibs/
* download the installable based on python version + Windows 32 or 64 bit, for example download xgboost-0.71-cp36-cp36m-win_amd64.whl for python version 3.6 and 64 bit machine.
* open cmd in downloaded location and run the following command: pip install xgboost-0.71-cp36-cp36m-win_amd64.whl

### Spark

* Why should one use spark for ML: https://www.infoworld.com/article/3031690/analytics/why-you-should-use-spark-for-machine-learning.html

* Multi-Class Text Classification with PySpark: https://towardsdatascience.com/multi-class-text-classification-with-pyspark-7d78d022ed35

### Python
* Python OOP tutorial: https://www.youtube.com/watch?v=ZDa-Z5JzLYM
* vectorized string operations in Python(using pandas): https://jakevdp.github.io/PythonDataScienceHandbook/03.10-working-with-strings.html

* Use YouTube as a Free Screencast Recorder: https://www.youtube.com/watch?v=0i9C8GpRedc

* list comprehensions: https://www.machinelearningplus.com/python/list-comprehensions-in-python/
* Numpy 1 - basic: https://www.machinelearningplus.com/python/numpy-tutorial-part1-array-python-examples/
* Numpy 2 - advanced: https://www.machinelearningplus.com/python/numpy-tutorial-python-part2/
* Numpy 101 practice: https://www.machinelearningplus.com/python/101-numpy-exercises-python/
* Pandas 101 practice: https://www.machinelearningplus.com/python/101-pandas-exercises-python/

* Parallel processing in Python: https://www.machinelearningplus.com/python/parallel-processing-python/

#### Generators
* Jeff Knup's blog: 'Yield' and Generator Functions: https://jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/
* Corey Schafer (YouTube video): Generator functions: https://www.youtube.com/watch?v=bD05uGo_sVI

### Reinforcement Learning

* Dynamic Programming: https://web.stanford.edu/class/cs97si/04-dynamic-programming.pdf
* When are Monte Carlo methods preferred over Temporal Difference methods: https://stats.stackexchange.com/questions/336974/when-are-monte-carlo-methods-preferred-over-temporal-difference-ones
* https://simoninithomas.github.io/Deep_reinforcement_learning_Course/#
* Off-Policy Monte Carlo Control: https://cs.wmich.edu/~trenary/files/cs5300/RLBook/node56.html
* https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/


## References (business):
* What is an ad impression: https://www.mediapost.com/publications/article/219695/the-definition-of-an-ad-impression.html
* ML in fraud detection: https://www.marutitech.com/machine-learning-fraud-detection/
* Customer Segmentation: http://analyticstraining.com/2011/cluster-analysis-for-business/
* Telecom churn customer model: https://parcusgroup.com/Telecom-Customer-Churn-Prediction-Models
* customer churn in mobile markets: https://arxiv.org/ftp/arxiv/papers/1607/1607.07792.pdf
